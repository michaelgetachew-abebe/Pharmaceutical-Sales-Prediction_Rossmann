{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#notebook reproducible \n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# preprocessing and feature engineering\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "\n",
    "\n",
    "# modeling\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# visualization\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib import rc\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from pandas_profiling import ProfileReport\n",
    "from pylab import rcParams\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "rcParams['figure.figsize'] = 22, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_processed.csv', parse_dates=['Date'])\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "print(f\"The dataset contains {len(df)} Sales Data\")\n",
    "pd.set_option('display.max_columns', len(df.columns)) # To view all columns , , index_col='Date'\n",
    "pd.set_option('display.max_rows', 100)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(['Date'])\n",
    "df.sort_values(by='Date', ascending = True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['Date', 'Sales']]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.Date = pd.to_datetime(df2.Date)\n",
    "df2 = df2[df2['Sales'] > 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df2.plot(x='Date', figsize=(20, 15))\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.title(\"Sales\", fontsize=16)\n",
    "plt.legend(fontsize=14);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df2) * 0.70)\n",
    "test_size = len(df2) - train_size\n",
    "train, testt = df2.iloc[0:train_size], df2.iloc[train_size:len(df2)]\n",
    "print(train.shape, testt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(len(testt) * 0.50)\n",
    "val_size = len(testt) - test_size\n",
    "test, val = testt.iloc[0:test_size], testt.iloc[test_size:len(testt)]\n",
    "print(val.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(train[['Sales']])\n",
    "\n",
    "train['Sales'] = scaler.transform(train[['Sales']])\n",
    "test['Sales'] = scaler.transform(test[['Sales']])\n",
    "val['Sales'] = scaler.transform(val[['Sales']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS=30\n",
    "\n",
    "def create_sequences(X, y, time_steps=TIME_STEPS):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X)-time_steps):\n",
    "        Xs.append(X.iloc[i:(i+time_steps)].values)\n",
    "        ys.append(y.iloc[i+time_steps])\n",
    "    \n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# X_train, y_train = create_sequences(updated_df_drop[['Close_scaled']], updated_df_drop['Close_scaled'])\n",
    "\n",
    "\n",
    "X_train, y_train = create_sequences(train[['Sales']], train['Sales'])\n",
    "X_test, y_test = create_sequences(test[['Sales']], test['Sales'])\n",
    "X_val, y_val = create_sequences(val[['Sales']], val['Sales'])\n",
    "\n",
    "print(f'Training shape: {X_train.shape}')\n",
    "print(f'Testing shape: {X_test.shape}')\n",
    "print(f'Testing shape: {X_val.shape}')\n",
    "\n",
    "print(f'Testing shape: {y_train.shape}')\n",
    "print(f'Testing shape: {y_test.shape}')\n",
    "print(f'Testing shape: {y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(RepeatVector(X_train.shape[1]))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(TimeDistributed(Dense(X_train.shape[2])))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, epsilon=1e-08, decay=0.01), loss='mae')\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
