{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dvc.api\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import logging\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "#cwd = os.getcwd()\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\n",
    "sys.path.append(os.path.abspath(os.path.join('../data')))\n",
    "\n",
    "from data_preprocess import preprocess\n",
    "from logger_creator import log\n",
    "from loss_functions import rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO Random Forest is Rolling....\n"
     ]
    }
   ],
   "source": [
    "data_version = \"version1\"\n",
    "data_url = dvc.api.get_url(\n",
    "    path = 'data/train_store.csv',\n",
    "    repo = 'https://github.com/michaelgetachew-abebe/Pharmaceutical-Sales-Prediction_Rossmann'\n",
    ")\n",
    "\n",
    "logger = log(path = '../logs/', file = 'randomforestregressor_log.log')\n",
    "logger.info(\"Random Forest is Rolling....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/09 16:16:32 INFO mlflow.tracking.fluent: Experiment with name 'Pharmaceutical sales prediction accros multiple stores in case of Rosemann Pharmaceuticals' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/mikyg/OneDrive/Desktop/10%20Acadamy/Week%203/Pharmaceutical-Sales-Prediction_Rossmann/models/mlruns/1', experiment_id='1', lifecycle_stage='active', name=('Pharmaceutical sales prediction accros multiple stores in case of Rosemann '\n",
       " 'Pharmaceuticals'), tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Pharmaceutical sales prediction accros multiple stores in case of Rosemann Pharmaceuticals\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'Date' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mikyg\\OneDrive\\Desktop\\10 Acadamy\\Week 3\\Pharmaceutical-Sales-Prediction_Rossmann\\models\\Random_Forest.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mikyg/OneDrive/Desktop/10%20Acadamy/Week%203/Pharmaceutical-Sales-Prediction_Rossmann/models/Random_Forest.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_store \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m../data/train_store.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, parse_dates\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, index_col\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mDate\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mikyg/OneDrive/Desktop/10%20Acadamy/Week%203/Pharmaceutical-Sales-Prediction_Rossmann/models/Random_Forest.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_store\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1235\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1232\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1234\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1235\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions)\n\u001b[0;32m   1236\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1237\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:153\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_parse_dates_presence(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames)  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_noconvert_columns()\n\u001b[0;32m    155\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morig_names \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:208\u001b[0m, in \u001b[0;36mCParserWrapper._set_noconvert_columns\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    206\u001b[0m col_indices \u001b[39m=\u001b[39m [names_dict[x] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames]  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m noconvert_columns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_noconvert_dtype_columns(\n\u001b[0;32m    209\u001b[0m     col_indices,\n\u001b[0;32m    210\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnames,  \u001b[39m# type: ignore[has-type]\u001b[39;49;00m\n\u001b[0;32m    211\u001b[0m )\n\u001b[0;32m    212\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m noconvert_columns:\n\u001b[0;32m    213\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39mset_noconvert(col)\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:673\u001b[0m, in \u001b[0;36mParserBase._set_noconvert_dtype_columns\u001b[1;34m(self, col_indices, names)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_col, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    672\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_col:\n\u001b[1;32m--> 673\u001b[0m         noconvert_columns\u001b[39m.\u001b[39madd(_set(k))\n\u001b[0;32m    674\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_col \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    675\u001b[0m     noconvert_columns\u001b[39m.\u001b[39madd(_set(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_col))\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:650\u001b[0m, in \u001b[0;36mParserBase._set_noconvert_dtype_columns.<locals>._set\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    647\u001b[0m     x \u001b[39m=\u001b[39m usecols[x]\n\u001b[0;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_integer(x):\n\u001b[1;32m--> 650\u001b[0m     x \u001b[39m=\u001b[39m col_indices[names\u001b[39m.\u001b[39;49mindex(x)]\n\u001b[0;32m    652\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[1;31mValueError\u001b[0m: 'Date' is not in list"
     ]
    }
   ],
   "source": [
    "train_store = pd.read_csv('../data/train_store.csv', parse_dates=True, index_col=0)\n",
    "train_store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"main\":\n",
    "    train_store = pd.read_csv('../data/train_store.csv, parse_dates=True, index_col=0')\n",
    "    mlflow.log_param('data_version', data_version)\n",
    "    mlflow.log_param('model_type', 'Random Forest Reressor')\n",
    "    mlflow.log_param('data_url', data_url)\n",
    "\n",
    "    test = pd.read_csv('../data/test.csv', parse_date = True, index_col = \"Date\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_store, test, test_size=0.2, random_state=20)\n",
    "    logger.info(\"Training and testing split was successful.\")\n",
    "    mlflow.log_param(\"Input columns:\", X_train.shape[0])\n",
    "    mlflow.log_param(\"Input rows:\", X_train.shape[1])\n",
    "\n",
    "    randomforestregressor = RandomForestRegressor(\n",
    "        n_estimators = 60,\n",
    "        criterion = 'mse',\n",
    "        max_depth = 15,\n",
    "        min_samples_leaf = 1,\n",
    "        min_samples_split = 2,\n",
    "        min_weight_fraction_leaf = 0.0,\n",
    "        max_features = 'auto',\n",
    "        max_leaf_nodes = None,\n",
    "        min_impurity_decrease = 0.0,\n",
    "        min_impurity_split = None,\n",
    "        bootstrap = True,\n",
    "        oob_score = False,\n",
    "        n_jobs = 4,\n",
    "        random_state = 18,\n",
    "        verbose = 0,\n",
    "        warm_start = False)\n",
    "    \n",
    "    randomforestregressor.fit(X_train, y_train)\n",
    "    logger.info(\"Model fitting completed successfully\")\n",
    "    mlflow.sklearn.log_model(randomforestregressor, \"Random Forest Regressor Model\")\n",
    "\n",
    "    #Prediction and Evaluation of the model\n",
    "    ybar = randomforestregressor(X_test)\n",
    "    prediction_error = rmse(y_test, ybar)\n",
    "\n",
    "    logger.info(f\"Model Prediction Error{prediction_error}\")\n",
    "    mlflow.log_param(\"Model Prediction Error\", prediction_error)\n",
    "    with open(\"Random_forest_regressor.txt\", \"w\") as outfile:\n",
    "        outfile.write(\"Model Prediction Error in:\" + str(prediction_error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b1e457b8bfb0f1a80baef745a8b0e3e0434ec352b0bd03e5bd8b3ada5f38a19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
