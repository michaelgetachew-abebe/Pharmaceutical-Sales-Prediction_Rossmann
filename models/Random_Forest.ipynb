{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dvc.api\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import logging\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "#cwd = os.getcwd()\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\n",
    "sys.path.append(os.path.abspath(os.path.join('../data')))\n",
    "\n",
    "from data_preprocess import preprocess\n",
    "from logger_creator import log\n",
    "from loss_functions import rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO Random Forest is Rolling....\n"
     ]
    }
   ],
   "source": [
    "data_version = \"version1\"\n",
    "data_url = dvc.api.get_url(\n",
    "    path = 'data/train_store.csv',\n",
    "    repo = 'https://github.com/michaelgetachew-abebe/Pharmaceutical-Sales-Prediction_Rossmann'\n",
    ")\n",
    "\n",
    "logger = log(path = '../logs/', file = 'randomforestregressor_log.log')\n",
    "logger.info(\"Random Forest is Rolling....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/09 16:16:32 INFO mlflow.tracking.fluent: Experiment with name 'Pharmaceutical sales prediction accros multiple stores in case of Rosemann Pharmaceuticals' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/mikyg/OneDrive/Desktop/10%20Acadamy/Week%203/Pharmaceutical-Sales-Prediction_Rossmann/models/mlruns/1', experiment_id='1', lifecycle_stage='active', name=('Pharmaceutical sales prediction accros multiple stores in case of Rosemann '\n",
       " 'Pharmaceuticals'), tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Pharmaceutical sales prediction accros multiple stores in case of Rosemann Pharmaceuticals\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/train_store.csv', parse_dates=True, index_col=0)\n",
    "data.head()\n",
    "mlflow.log_param('data_version', data_version)\n",
    "mlflow.log_param('model_type', 'Random Forest Reressor')\n",
    "mlflow.log_param('data_url', data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['Date'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mikyg\\OneDrive\\Desktop\\10 Acadamy\\Week 3\\Pharmaceutical-Sales-Prediction_Rossmann\\models\\Random_Forest.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mikyg/OneDrive/Desktop/10%20Acadamy/Week%203/Pharmaceutical-Sales-Prediction_Rossmann/models/Random_Forest.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data\u001b[39m.\u001b[39;49mset_index(\u001b[39m'\u001b[39;49m\u001b[39mDate\u001b[39;49m\u001b[39m'\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mikyg/OneDrive/Desktop/10%20Acadamy/Week%203/Pharmaceutical-Sales-Prediction_Rossmann/models/Random_Forest.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m data\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mStateHoliday\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mikyg/OneDrive/Desktop/10%20Acadamy/Week%203/Pharmaceutical-Sales-Prediction_Rossmann/models/Random_Forest.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m data \u001b[39m=\u001b[39m data[data[\u001b[39m'\u001b[39m\u001b[39mOpen\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:5494\u001b[0m, in \u001b[0;36mDataFrame.set_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   5491\u001b[0m                 missing\u001b[39m.\u001b[39mappend(col)\n\u001b[0;32m   5493\u001b[0m \u001b[39mif\u001b[39;00m missing:\n\u001b[1;32m-> 5494\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of \u001b[39m\u001b[39m{\u001b[39;00mmissing\u001b[39m}\u001b[39;00m\u001b[39m are in the columns\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5496\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   5497\u001b[0m     frame \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['Date'] are in the columns\""
     ]
    }
   ],
   "source": [
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "data.drop(['StateHoliday'], axis=1, inplace=True)\n",
    "\n",
    "data = data[data['Open'] == 1]\n",
    "data = data[data['Sales'] > 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Sales', axis=1)\n",
    "y = data['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO Training and testing split was successful.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "logger.info(\"Training and testing split was successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')), ('scaler', StandardScaler())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', data_transformer), ('regressor',\n",
    "                                            RandomForestRegressor(n_estimators=12, random_state=42))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mikyg\\OneDrive\\Desktop\\10 Acadamy\\Week 3\\Pharmaceutical-Sales-Prediction_Rossmann\\models\\Random_Forest.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mikyg/OneDrive/Desktop/10%20Acadamy/Week%203/Pharmaceutical-Sales-Prediction_Rossmann/models/Random_Forest.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m random_foreset_regrssion_model \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:390\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \n\u001b[0;32m    366\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    389\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m--> 390\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps)\n\u001b[0;32m    391\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[0;32m    392\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:348\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    346\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[0;32m    347\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 348\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    349\u001b[0m     cloned_transformer,\n\u001b[0;32m    350\u001b[0m     X,\n\u001b[0;32m    351\u001b[0m     y,\n\u001b[0;32m    352\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    353\u001b[0m     message_clsname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    354\u001b[0m     message\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    355\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    356\u001b[0m )\n\u001b[0;32m    357\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit_transform(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:426\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \n\u001b[0;32m    401\u001b[0m \u001b[39mFits all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[39m    Transformed samples.\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    425\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m--> 426\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps)\n\u001b[0;32m    428\u001b[0m last_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\n\u001b[0;32m    429\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:348\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    346\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[0;32m    347\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 348\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    349\u001b[0m     cloned_transformer,\n\u001b[0;32m    350\u001b[0m     X,\n\u001b[0;32m    351\u001b[0m     y,\n\u001b[0;32m    352\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    353\u001b[0m     message_clsname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    354\u001b[0m     message\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    355\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    356\u001b[0m )\n\u001b[0;32m    357\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit_transform(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\sklearn\\base.py:855\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    852\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    853\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    854\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 855\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py:319\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    303\u001b[0m     \u001b[39m\"\"\"Fit the imputer on `X`.\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \n\u001b[0;32m    305\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_input(X, in_fit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    321\u001b[0m     \u001b[39m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39m# otherwise\u001b[39;00m\n\u001b[0;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mikyg\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py:285\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcould not convert\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(ve):\n\u001b[0;32m    280\u001b[0m     new_ve \u001b[39m=\u001b[39m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot use \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m strategy with non-numeric data:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    282\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy, ve\n\u001b[0;32m    283\u001b[0m         )\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 285\u001b[0m     \u001b[39mraise\u001b[39;00m new_ve \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    286\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    287\u001b[0m     \u001b[39mraise\u001b[39;00m ve\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'a'"
     ]
    }
   ],
   "source": [
    "random_foreset_regrssion_model = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_store, test, test_size=0.2, random_state=20)\n",
    "    logger.info(\"Training and testing split was successful.\")\n",
    "    mlflow.log_param(\"Input columns:\", X_train.shape[0])\n",
    "    mlflow.log_param(\"Input rows:\", X_train.shape[1])\n",
    "\n",
    "    randomforestregressor = RandomForestRegressor(\n",
    "        n_estimators = 60,\n",
    "        criterion = 'mse',\n",
    "        max_depth = 15,\n",
    "        min_samples_leaf = 1,\n",
    "        min_samples_split = 2,\n",
    "        min_weight_fraction_leaf = 0.0,\n",
    "        max_features = 'auto',\n",
    "        max_leaf_nodes = None,\n",
    "        min_impurity_decrease = 0.0,\n",
    "        min_impurity_split = None,\n",
    "        bootstrap = True,\n",
    "        oob_score = False,\n",
    "        n_jobs = 4,\n",
    "        random_state = 18,\n",
    "        verbose = 0,\n",
    "        warm_start = False)\n",
    "    \n",
    "    randomforestregressor.fit(X_train, y_train)\n",
    "    logger.info(\"Model fitting completed successfully\")\n",
    "    mlflow.sklearn.log_model(randomforestregressor, \"Random Forest Regressor Model\")\n",
    "\n",
    "    #Prediction and Evaluation of the model\n",
    "    ybar = randomforestregressor(X_test)\n",
    "    prediction_error = rmse(y_test, ybar)\n",
    "\n",
    "    logger.info(f\"Model Prediction Error{prediction_error}\")\n",
    "    mlflow.log_param(\"Model Prediction Error\", prediction_error)\n",
    "    with open(\"Random_forest_regressor.txt\", \"w\") as outfile:\n",
    "        outfile.write(\"Model Prediction Error in:\" + str(prediction_error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b1e457b8bfb0f1a80baef745a8b0e3e0434ec352b0bd03e5bd8b3ada5f38a19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
